{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2b5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import csv\n",
    "import scipy\n",
    "\n",
    "import numerapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "NAPI = numerapi.NumerAPI(verbosity=\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_current_data():\n",
    "        \"\"\"\n",
    "        Downloads the data for the current round\n",
    "        :param directory: The path to the directory where the data needs to be saved\n",
    "        \"\"\"\n",
    "        current_round = NAPI.get_current_round()\n",
    "        if os.path.isdir(f'/numerai_dataset_{current_round}/'):\n",
    "            print(f\"You already have the newest data! Current round is: {current_round}\")\n",
    "        else:\n",
    "            print(f\"Downloading new data for round: {current_round}!\")\n",
    "            NAPI.download_current_dataset(unzip=True)\n",
    "\n",
    "def load_data(reduce_memory: bool=True) -> tuple:\n",
    "        \"\"\"\n",
    "        Get data for current round\n",
    "        :param directory: The path to the directory where the data needs to be saved\n",
    "        :return: A tuple containing the datasets\n",
    "        \"\"\"\n",
    "        print('Loading the data')\n",
    "        full_path = f'numerai_dataset_{NAPI.get_current_round()}/'\n",
    "        train_path = full_path + 'numerai_training_data.csv'\n",
    "        test_path = full_path + 'numerai_tournament_data.csv'\n",
    "        train = pd.read_csv(train_path)\n",
    "        test = pd.read_csv(test_path)\n",
    "        # Reduce all features to 32-bit floats\n",
    "        if reduce_memory:\n",
    "            num_features = [f for f in train.columns if f.startswith(\"feature\")]\n",
    "            train[num_features] = train[num_features].astype(np.float32)\n",
    "            test[num_features] = test[num_features].astype(np.float32)\n",
    "        val = test[test['data_type'] == 'validation']\n",
    "        test = test[test['data_type'] != 'validation']\n",
    "        return train, val, test\n",
    "\n",
    "# Download, unzip and load data\n",
    "download_current_data()\n",
    "train, val, test = load_data(reduce_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77930473",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOURNAMENT_NAME = \"nomi\"\n",
    "TARGET_NAME = f\"target\"\n",
    "PREDICTION_NAME = f\"prediction\"\n",
    "\n",
    "BENCHMARK = 0\n",
    "BAND = 0.2\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Submissions are scored by spearman correlation\n",
    "def score(df):\n",
    "    # method=\"first\" breaks ties based on order in array\n",
    "    return np.corrcoef(\n",
    "        df[TARGET_NAME],\n",
    "        df[PREDICTION_NAME].rank(pct=True, method=\"first\")\n",
    "    )[0, 1]\n",
    "\n",
    "def correlation(predictions, targets):\n",
    "    ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
    "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
    "\n",
    "# The payout function\n",
    "def payout(scores):\n",
    "    return ((scores - BENCHMARK) / BAND).clip(lower=-1, upper=1)\n",
    "\n",
    "\n",
    "\n",
    "def read_csv(file_path):\n",
    "    \"\"\"An efficient way to load csv.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        column_names = next(csv.reader(f))\n",
    "        dtypes = {x: np.float16 for x in column_names if\n",
    "                  x.startswith(('feature', 'target'))}\n",
    "    return pd.read_csv(file_path, dtype=dtypes)\n",
    "\n",
    "\n",
    "def get_group_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        for group in [\"intelligence\", \"wisdom\", \"charisma\", \"dexterity\", \"strength\", \"constitution\"]:\n",
    "            cols = [col for col in df.columns if group in col]\n",
    "            df.loc[:,f\"feature_{group}_mean\"] = df[cols].mean(axis=1)\n",
    "            df.loc[:,f\"feature_{group}_median\"] = df[cols].median(axis=1)\n",
    "            df.loc[:,f\"feature_{group}_std\"] = df[cols].std(axis=1)\n",
    "            df.loc[:,f\"feature_{group}_skew\"] = df[cols].skew(axis=1)\n",
    "            df.loc[:,f\"feature_{group}_p25\"] = df[cols].quantile(0.25, axis=1)\n",
    "            df.loc[:,f\"feature_{group}_p75\"] = df[cols].quantile(0.75, axis=1)\n",
    "        return df\n",
    "\n",
    "    \n",
    "def power_vars(df: pd.DataFrame, power: int) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if col in feature_names:\n",
    "            df.loc[:,f\"{col}_squared\"] = df[col] ** power\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def squared_root_vars(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in df.columns:\n",
    "        if col in feature_names:\n",
    "            df.loc[:,f\"{col}_squared_root\"] = np.sqrt(df[col])\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def yeo_transformation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "    df_trans = pd.DataFrame(power.fit_transform(df[feature_names]))\n",
    "    # rename columns\n",
    "    df_trans.rename(columns=dict(zip(df_trans.columns, [f\"{f}_yeo\" for f in feature_names])), inplace=True)\n",
    "    # concat with main dataset\n",
    "    df = pd.concat([df.reset_index(), df_trans], axis=1).set_index('id')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def sharpe_ratio(corrs: pd.Series) -> np.float32:\n",
    "        \"\"\"\n",
    "        Calculate the Sharpe ratio for Numerai by using grouped per-era data\n",
    "\n",
    "        :param corrs: A Pandas Series containing the Spearman correlations for each era\n",
    "        :return: A float denoting the Sharpe ratio of your predictions.\n",
    "        \"\"\"\n",
    "        return corrs.mean() / corrs.std()\n",
    "\n",
    "\n",
    "def evaluate(df: pd.DataFrame) -> tuple:\n",
    "        \"\"\"\n",
    "        Evaluate and display relevant metrics for Numerai \n",
    "\n",
    "        :param df: A Pandas DataFrame containing the columns \"era\", \"target\" and a column for predictions\n",
    "        :param pred_col: The column where the predictions are stored\n",
    "        :return: A tuple of float containing the metrics\n",
    "        \"\"\"\n",
    "        def _score(sub_df: pd.DataFrame) -> np.float32:\n",
    "            \"\"\"Calculates Spearman correlation\"\"\"\n",
    "            return spearmanr(sub_df[\"target\"], sub_df[\"prediction\"])[0]\n",
    "\n",
    "        # Calculate metrics\n",
    "        corrs = df.groupby(\"era\").apply(_score)\n",
    "        print(corrs)\n",
    "        payout_raw = (corrs / 0.2).clip(-1, 1)\n",
    "        spearman = round(corrs.mean(), 4)\n",
    "\n",
    "        payout = round(payout_raw.mean(), 4)\n",
    "        numerai_sharpe = round(sharpe_ratio(corrs), 4)\n",
    "        mae = mean_absolute_error(df[\"target\"], df[\"prediction\"]).round(4)\n",
    "\n",
    "        # Display metrics\n",
    "        print(f\"Spearman Correlation: {spearman}\")\n",
    "        print(f\"Average Payout: {payout}\")\n",
    "        print(f\"Sharpe Ratio: {numerai_sharpe}\")\n",
    "        print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "        return spearman, payout, numerai_sharpe, mae\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7010c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "napi = numerapi.NumerAPI(verbosity=\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef93a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download current dataset\n",
    "# napi.download_current_dataset(unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the latest round information\n",
    "current_ds = napi.get_current_round()\n",
    "latest_round = os.path.join('numerai_dataset_'+str(current_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2744b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading \n",
    "print(\"# Loading data...\")\n",
    "# The training data is used to train your model how to predict the targets.\n",
    "training_data = read_csv(os.path.join(latest_round, \"numerai_training_data.csv\")).set_index(\"id\")\n",
    "# The tournament data is the data that Numerai uses to evaluate your model.\n",
    "tournament_data = read_csv(os.path.join(latest_round, \"numerai_tournament_data.csv\")).set_index(\"id\")\n",
    "# example_preds = read_csv(os.path.join(latest_round, \"example_predictions_target_kazutsugi.csv\")\n",
    "validation_data = tournament_data[tournament_data.data_type == \"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [f for f in train.columns if f.startswith(\"feature\")]\n",
    "print(f\"Loaded {len(feature_names)} features\")\n",
    "cols = feature_names+[TARGET_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ee273",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_group_stats(train)\n",
    "val = get_group_stats(val)\n",
    "test = get_group_stats(test)\n",
    "\n",
    "train = power_vars(train, 2)\n",
    "val = power_vars(val, 2)\n",
    "test = power_vars(test, 2)\n",
    "\n",
    "train = squared_root_vars(train)\n",
    "val = squared_root_vars(val)\n",
    "test = squared_root_vars(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe6a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for Catboost\n",
    "params = {\n",
    "    'iterations':[5000],\n",
    "    'depth':sp_randint(3,15), \n",
    "    'learning_rate': sp_uniform(0.005, 0.15),\n",
    "    'reg_lambda': sp_randint(1, 5),\n",
    "    'use_best_model':[True],\n",
    "    'min_data_in_leaf': sp_randint(1, 5)\n",
    "}\n",
    "\n",
    "fit_params={\"early_stopping_rounds\":15, \n",
    "            \"eval_set\" :[(validation_data.drop(['era','data_type','target'], axis=1).astype(np.float32), validation_data[TARGET_NAME].astype(np.float32))]}\n",
    "\n",
    "reg = CatBoostRegressor()\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 30\n",
    "random_search = RandomizedSearchCV(reg, \n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=n_iter_search, \n",
    "                                   cv=3, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   verbose=2)\n",
    "\n",
    "random_search.fit(training_data.drop(['era','data_type','target'], axis=1).astype(np.float32), training_data[TARGET_NAME].astype(np.float32), **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da041d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9541a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(gs, 'models/catboost_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639bb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'depth': 5,\n",
    " 'iterations': 250,\n",
    " 'learning_rate': 0.036878060835166426,\n",
    " 'min_data_in_leaf': 1,\n",
    " 'reg_lambda': 1}\n",
    "\n",
    "model = CatBoostRegressor(**params)\n",
    "model.fit(training_data.drop(['era','data_type','target'], axis=1).astype(np.float32),\n",
    "          training_data[TARGET_NAME].astype(np.float32),\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating predictions on tournament data...\")\n",
    "tournament_preds = model.predict(tournament_data.drop(['era','data_type','target'], axis=1).astype(np.float32))\n",
    "# tournament_data[PREDICTION_NAME] = tournament_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4957a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = tournament_data.drop(['era','data_type','target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_preds = model.predict(aux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d142b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = tournament_data.drop(['era','data_type','target'], axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2869b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Generating predictions on training data...\")\n",
    "# training_preds = model.predict(training_data.drop(['era','data_type','target'], axis=1).astype(np.float32).astype(np.float32))\n",
    "# training_data[PREDICTION_NAME] = training_preds\n",
    "# gc.collect()\n",
    "\n",
    "print(\"Generating predictions on tournament data...\")\n",
    "tournament_preds = model.predict(tournament_data.drop(['era','data_type','target'], axis=1).astype(np.float32))\n",
    "tournament_data[PREDICTION_NAME] = tournament_preds\n",
    "\n",
    "# # Check the per-era correlations on the training set (in sample)\n",
    "# train_correlations = training_data.groupby(\"era\").apply(score)\n",
    "# print(f\"On training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
    "# print(f\"On training the average per-era payout is {payout(train_correlations).mean()}\")\n",
    "\n",
    "# Check the per-era correlations on the validation set (out of sample)\n",
    "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
    "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations.mean()} and \"\n",
    "        f\"std {validation_correlations.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations).mean()}\")\n",
    "\n",
    "#FEAT_EXPOSURE:\n",
    "corr_list = []\n",
    "for feature in feature_names:\n",
    "    corr_list.append(np.corrcoef(tournament_data[feature].values, tournament_data[PREDICTION_NAME])[0,1])\n",
    "corr_series = pd.Series(corr_list, index=feature_names)\n",
    "print(\"Feat. exposure: \", corr_series.describe()['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253be5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa35d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A parameter grid for Catboost\n",
    "params = {\n",
    "    'num_leaves': sp_randint(5,50),\n",
    "    'max_depth': sp_randint(3,20), \n",
    "    'learning_rate': sp_uniform(0.0005, 0.15),\n",
    "    'reg_lambda': sp_uniform(0, 5),\n",
    "    'n_estimators':[5000]\n",
    "}\n",
    "\n",
    "feature_list = train.columns.drop(['id','era','data_type','target'])\n",
    "\n",
    "fit_params={\"early_stopping_rounds\":15, \n",
    "            \"eval_set\" :[(val[feature_list].fillna(0), val['target'])],\n",
    "            \"eval_metric\": \"None\"}\n",
    "\n",
    "reg = lgb.LGBMRegressor(random_state=314)\n",
    "\n",
    "print(\"Running random search...\")\n",
    "# run randomized search\n",
    "n_iter_search = 1\n",
    "random_search = RandomizedSearchCV(reg, \n",
    "                                   param_distributions=params,\n",
    "                                   n_iter=n_iter_search, \n",
    "                                   cv=3, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   verbose=2)\n",
    "\n",
    "random_search.fit(train[feature_list].fillna(0), train['target'], **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = train.columns.drop(['id','era','data_type','target'])\n",
    "dtrain = lgb.Dataset(train[feature_list].fillna(0), label=train[\"target\"])\n",
    "dvalid = lgb.Dataset(val[feature_list].fillna(0), label=val[\"target\"])\n",
    "\n",
    "best_config ={\"objective\":\"regression\",\"learning_rate\":0.01,\"n_estimators\":250,\"max_depth\":5,\"metric\":\"mse\",\"verbosity\": 10, \"random_state\": 0} \n",
    "\n",
    "model = lgb.train(best_config, dtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17a91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, \"prediction\"] = random_search.predict(train[feature_list])\n",
    "\n",
    "val.loc[:,\"prediction\"]=val[\"target\"]\n",
    "val.loc[:,\"prediction\"] = random_search.predict(val[feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spearman_val = [spearmanr(val[\"prediction\"], val[f])[0] for f in feature_list]\n",
    "feature_exposure_val = np.std(feature_spearman_val).round(4)\n",
    "spearman, payout, numerai_sharpe, mae = evaluate(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be0c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42157ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cboost = joblib.load('models/catboost.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e9b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d356552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "# max_features = ['log2', 'sqrt']\n",
    "# max_depth = [int(x) for x in np.linspace(start = 1, stop = 15, num = 15)]\n",
    "# min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
    "# min_samples_leaf = [int(x) for x in np.linspace(start = 2, stop = 50, num = 10)]\n",
    "# bootstrap = [True, False]\n",
    "# param_dist = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# rfc = RandomForestRegressor()\n",
    "\n",
    "# rs = RandomizedSearchCV(rfc, \n",
    "#                         param_dist, \n",
    "#                         n_iter = 100, \n",
    "#                         cv = 3, \n",
    "#                         verbose = 1, \n",
    "#                         random_state=314)\n",
    "# rs.fit(training_data.drop(['era','data_type','target'], axis=1), training_data[TARGET_NAME])\n",
    "# rs.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb98d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b6824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7abc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating predictions on training data...\")\n",
    "training_preds = random_search.predict(training_data[feature_names])\n",
    "training_data[PREDICTION_NAME] = training_preds\n",
    "gc.collect()\n",
    "\n",
    "print(\"Generating predictions on tournament data...\")\n",
    "tournament_preds = random_search.predict(tournament_data[feature_names])\n",
    "tournament_data[PREDICTION_NAME] = tournament_preds\n",
    "\n",
    "# Check the per-era correlations on the training set (in sample)\n",
    "train_correlations = training_data.groupby(\"era\").apply(score)\n",
    "print(f\"On training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
    "print(f\"On training the average per-era payout is {payout(train_correlations).mean()}\")\n",
    "\n",
    "# Check the per-era correlations on the validation set (out of sample)\n",
    "validation_data = tournament_data[tournament_data.data_type == \"validation\"]\n",
    "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations.mean()} and \"\n",
    "        f\"std {validation_correlations.std()}\")\n",
    "print(f\"On validation the average per-era payout is {payout(validation_correlations).mean()}\")\n",
    "\n",
    "#FEAT_EXPOSURE:\n",
    "corr_list = []\n",
    "for feature in feature_names:\n",
    "    corr_list.append(np.corrcoef(tournament_data[feature].values, tournament_data[PREDICTION_NAME])[0,1])\n",
    "corr_series = pd.Series(corr_list, index=feature_names)\n",
    "print(\"Feat. exposure: \", corr_series.describe()['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12713276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae6197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51c0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'logloss', \n",
    "            \"eval_set\" : [(validation_data[feature_names],validation_data[TARGET_NAME])],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ab770",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5929c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMRegressor(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, \n",
    "    param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='logloss',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(training_data[feature_names], training_data[TARGET_NAME], **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "\n",
    "lgb_estimator= lgb.LGBMRegressor(max_depth=-1, random_state=314, metric='None', n_estimators=5000, early_stopping_rounds=30)\n",
    "g_lgbm = RandomizedSearchCV(estimator=lgb_estimator, param_distributions=param_test, n_iter=60 ,n_jobs = 2, cv= 3, verbose=10)\n",
    "lgb_model = g_lgbm.fit(X=training_data[feature_names], y=training_data[TARGET_NAME], eval_set = (validation_data[feature_names],validation_data[TARGET_NAME]), eval_metric='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b5df95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
